TLS
答案：密钥交换、身份验证、对称加密，生成摘要


http传输优化
1.服务端选用高性能的Web服务器，如nginx，静态资源交给nginx；使用高速宽带以及程序使用缓存
  nginx禁用负载均衡锁、增大连接池，绑定CPU等。HTTP启用长连接，开启TCP的新特性“TCP Fast Open”
2.使用CDN节点节省DNS解析
3.客户端使用高速宽带
4.数据压缩算法，gzip和br是通用的压缩算法。资源合并把许多小资源合并成一个大资源，用一个请求全下载到客户端
5.重定向使用 Web 服务器的“内部重定向”

安全的四大特性：机密性、完整性、可用性和认证性。
1.数据完整性：使用摘要算法，对明文使用摘要算法生成摘要，使用会话密钥加密后传输
2.身份认证：签名。客户端使用私钥加密原文的摘要(减少运算)，服务端使用公钥解密实现“身份认证”和“不可否认”（验签）
3.公钥信任：CA证书认证机构,由它来给各个公钥签名
4.防止重放：服务器端维护一个已使用Nonce的列表、使用一次性密码（OTP）、双因素认证

为什么要这样加密的过程了
↓ 对称加密（有密钥交换的问题）
↓ 非对称加密（基于复杂的数学难题，运行速度很慢）
↓ 混合加密（怎么保证完整性？不被修改？）
↓ 摘要算法（无法保证是用户自己）
↓ 数字签名（公钥怎么保证安全正确的？）
↓ 数字证书、CA


https优化
硬件优化：更快的 CPU，最好还内建 AES 优化、SSL 加速卡、SSL 加速服务器
软件优化：Linux 内核、Nginx 、OpenSSL升级
协议优化：采用 TLS1.3
证书优化：证书传输，选择椭圆曲线（ECDSA）证书而不是 RSA 证书。
        证书验证，CRL证书吊销列表会越来越大，取而代之的是 OCSP（在线证书状态协议）向 CA 发送查询请求，让 CA 返回证书的有效状态。
                OCSP 也要多出一次网络请求的消耗，还依赖于 CA 服务器。
                最终选择OCSP Stapling”（OCSP 装订）让服务器预先访问 CA 获取 OCSP 响应，然后在握手时随着证书一起发给客户端
会话复用：TLS 一次握手重点是算出主密钥“Master Secret”，每次连接都要重新计算，将主密钥缓存，免去了握手和计算的成本。
        Session ID和Session Ticket，在TLS1.3废除，只能使用PSK。
        PSK，TLS连接后，服务器生成psk返回客户端，客户端下次发起连接使用psk导出的密钥进行数据加密，服务器使用psk解析。
            是session ticket强化，应用数据随ticket一起发给服务器，省去了中间服务器与客户端的确认步骤。


申请证书
1.同时申请 RSA 和 ECDSA 两种证书，在 Nginx 里配置成双证书验证，这样服务器可以自动选择快速的椭圆曲线证书，同时也兼容只支持 RSA 的客户端。
2.申请 RSA 证书，私钥至少要 2048 位，摘要算法应该选用 SHA-2，例如 SHA256、SHA384 等
3.必须要定期更新，crontab 里加个每周或每月任务，发送更新请求，不过很多 ACME 客户端会自动添加这样的定期任务，完全不用你操心。

包过滤防火墙
网络应用防火墙：开源的、生产级的ModSecurity
 IP 黑名单和白名单、URI 黑名单和白名单、URI 黑名单和白名单、过滤请求报文、过滤响应报文、审计日志
状态防火墙


CDN--命中、回源
权威 DNS 返回的不是 IP 地址，CDN返回CNAME( Canonical Name ) 别名记录，是 CDN 的 GSLB。
本地 DNS 就会向 GSLB 再发起请求，进入了 CDN 的全局负载均衡系统，开始智能调度
1.看用户的 IP 地址，查表得知地理位置，找相对最近的边缘节点；
2.看用户所在的运营商网络，找相同网络的边缘节点；
3.检查边缘节点的负载情况，找负载较轻的节点；
4.其他，比如节点的“健康状况”、服务能力、带宽、响应时间等。