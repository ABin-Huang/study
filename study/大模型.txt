1.什么是AIRC 系统
答案：策略建模、数据工程和模型工程

2.特征工程
回答：给数据集建模：通过将数据特征投影到高维空间，用非线性处理、特征组合处理和归一化处理等特征处理方法，让你的特征更好地服务于模型。
比如：人的兴趣，插花、篮球、绘画之间的关系

3.人工智能在学术上的三大学派
答案：符号主义学派、连接主义学派和行为主义学派。其中的代表分别是知识图谱、深度学习和强化学习。

对比学习（只需要得到样本之间的“相似度”就能完成训练，连接主义），监督学习（给参考答案，连接主义）
强化学习的核心思想，是利用感知和行动的闭环进行学习。行为主义

建知识图谱的三个主要步骤：知识抽取、知识融合和知识加工

4.构建大语言模型系统
答案：
1.利用外部记忆
2.高效存储和检索外部记忆 （知识表征技术-倒排索引,没有语义信息，受多义词干扰、嵌入表征，语义信息，无法表示段落和上下文内容、知识图谱，结构化学习和语义关联，难形成全文语义）


5.如何获取大模型训练数据
答案： Self-Instruct 方法
  1.使用一组人工编写的指令（本例中为 175 条）来初始化任务池，并随机选择一些指令。
  2.利用预训练的大型语言模型（如 GPT-3）来确定任务的类别。
  3.给定新的指令，让预训练的语言模型生成回应。
  4.在将回应添加到任务池之前，进行回应的收集、修剪和过滤。

6.GPT如何预训练模型
答案：基于Decoder Only 的 Transformer 架构，使用Word2Vec 词向量技术，将文本转换为向量，然后输入到模型中进行训练。结合ELMO 和GPT 的优点，使用双向语言模型，在训练中引入上下文信息。
对于完形填空等问题上显然存在一定的天然劣势。

7.BERT预训练模型
答案：基于Encoder Only 的 Transformer 架构，采用了类似 ELMo 的双向语言模型，同时利用上文和下文信息进行建模预测。

8.注意力机制和自注意力机制的区别是什么
答案：注意力机制是让模型在处理序列数据时，能够关注到不同位置的信息（输入与输出之间的关联）。
  自注意力机制是注意力机制的一种，它可以让模型在处理序列数据时，能够关注到不同位置的信息。（词与词之间的内部关联性），对翻译文本、语音识别、文本摘要、图像描述等任务效果显著。

9.大模型为什么会产生智能
答案：涌现 1.参数规模的影响，不同类型的任务在参数增加时，表现出了三种不同的特征，分别是伸缩、涌现和 U 形曲线效应。

两个最典型的涌现能力表现——ICL 和 CoT。
In Context Learning (ICL)：大语言模型从少量的示例中学习，而无需微调参数的能力。
思维链 (CoT)：大语言模型能够理解和执行复杂的推理过程。


10.怎么策略建模（内容的质量、生成内容的安全）
答案：为了完成这两个目标，我们需要使用提示语引擎、生成模块、控制模块和风控模块共同协作完成这个任务。
    策略建模是将业务的玄学问题转化为数学问题，进而把数学问题建模为工程问题的过程。
    1.搜索引擎的系统建模方式是通过用户请求，检索海量内容，之后呈现内容。
    2.AIGC 系统则是会先根据用户请求生成推理计划，之后，再通过检索海量内容为生成模型提供实时的外部记忆，
      随后再由模型生成内容，最后，再通过搜索引擎验证内容的可信性（搜索引擎适用于“避风港原则”），呈现给用户

11.提示语工程
答案：任务是针对用户的问题，对智能体的外部记忆进行排序，再将排名靠前的内容返回给大语言模型。
我们让 LLM 思考的方法类似于“产婆术”，所以我们唯一能和 LLM 进行互动的方式就是通过“提示语  Prompt”。

12.提示语引擎必备三种能力
答案；1.识别用户的意图，这需要对你的提示语工程和指令微调进行联合设计。负责生成计划
    2.识别和选择检索结果的能力，这个能力早在 WebGPT 时 OpenAI 就已开始探索了。获得外部记忆
    3.有效压缩有价值信息的能力，因为提示语长度的限制，我们需要用最少的 Token 保留最多的信息。
    原因：具备上述能力，才能获得所有用于问题回答的原材料。

13.生成模块
答案：1.需要准确地理解提示语引擎给它的指令。
    2.根据用户的指令为生成任务做具体分类，选择合适的专家模型做处理。
    3.拥有强大的涌现能力，将提示语的内容以及辅助外部信息有机地结合起来。
    4.基础的内容安全能力。防止生产具有内容安全风险的信息。

14.控制模块
答案：高效地标注用户反馈，还可以用于自动设置大模型在线服务的升降级策略，控制商业成本。
    为了赶上 ChatGPT 的数据收集和标注的速度，目前主流的在线大模型系统都采用了基于强化学习的增量模型训练方法。

15.风控模块
答案：1.内容的合规性和品牌安全性进行综合评估.
    2.攻击者可以对训练数据进行“投毒”影响你的模型训练效果，或者是使用对抗样本对你的模型进行越狱，突破安全屏障，甚至还会诱导你的模型生成注入指令，进而入侵你的系统。
    3.竞争对手利用大模型来标注自己的数据

16.提示语工程的核心目标
答案：基于 ICL（In-Context Learning） 的特点为 LLM 选择适当的少样本学习（Few-Shot）示例样本。
    1.为模型提供外部知识，也就是通过示例样本来进行少样本学习（Few-Shot Learning）。
    2.让模型理解指令任务，通过提示语策略，帮助模型解决复杂问题。

17.如何为模型优选示例样本
答案：AIRC 系统中通过召回和排序完成的，召回过程需要使用向量引擎，内容标签倒排索引和知识图谱等知识表达和知识检索方法。
    在提示引擎中我们第一步要做的工作就是围绕用户的需求，去检索这些最重要的外部数据，并将最优质的内容排在前面。
    优选：1.KATE（就近法则）在文本理解和文本生成任务上使用提问内容语义（高维空间距离）更相近的示例，能够帮助大语言模型得到更好的结果。
        2.EPR（因材施教）

    在某些测试中，不同排序的示例可能导致生成内容的质量大幅波动，工业界使用的排序策略：
        1.基于示例质量的排序、
        2.基于熵的排序方法（可以对一个示例样本的序列，计算它概率的熵值。熵值越大，就表示该序列的质）。
        全局熵（Global Entropy: GlobalE）和局部熵（Local Entropy: LocalE），跟随机排序的方法相比，
        可以分别平均提高 13% 和 9.6% 的性能。这种方法相较于“就近示例”方法更加复杂，但在理论上具有更强的可解释性，更适用于对稳定性要求较高的工业级系统。

18.工业界在 AIGC 系统的链路
答案：检索（为大语言模型提供外部记忆）-> 生成大语言模型的提示词模板-> CoT（思维链）生成提示语策略 -> 生成 -> 检索（为生成的内容提供引用信息）。
    第一次检索的输入是用户问题，目的是为大语言模型提供外部记忆；而第二次检索的输入则是生成内容，目的是为生成的内容提供引用信息，增加生成内容的可信度。
    CoT 是一种用于引导大语言模型进行推理的方法。CoT 通过提示词指示模型，生成一系列简短的句子来给出推理步骤。

19.优化 CoT 的过程
答案：CoT 提示可以约束大语言模型理解和遵循推理逻辑，从而提高推理任务的准确性。工业界在实践中发现，经过代码语料训练过的 LLM 具有更强的 CoT 能力。
     CoT 的优势在复杂的推理任务更明显，在使用大参数模型（比如 50B 以上的模型）时，这个优势则更明显。
     CoT 可以用一些动态的步骤生成答案，但是还是存在一些局限性。自一致采样（Self-Consistency Sampling）

20.为模型优选示例样本,如何使用提示语模板来组合你的示例和提问，让大语言模型更好地理解（提高模型的回答质量）
答案：工业级大模型系统的解决思路，使用自动提示词工程技术也就是 APE（Automatic Prompt Engineering）自动地生成一个更适合大语言模型的提示词模板。
    APE主要思想：1.需要提供示例，包括任务描述和任务示例，一般来说任务示例是一组输入输出对。大语言模型会根据提供的示例，生成一些备选的“提示语模板”。
               2.使用大语言模型作为打分模型，给每个提示语模板打分，选出分数最高的提示语模板作为这个任务的模板。
               3.改进模板，这里要使用迭代蒙特卡洛搜索的方法，针对刚刚生成好的提示语模板，生成语义相似的指令变体，改进最佳模板。

21.自动生成提示词模版之后的下一步，如何通过提示语控制大语言模型的“思考方式”
答案：Google 提出了自一致采样（Self-Consistency Sampling）的方法（提高模型的回答质量，又可以提高模型的鲁棒性），
    通过让 LLM 从多个不同的推理路径中生成答案，并根据答案的自洽性来选择最优的结果。
        1.用思维链（CoT）提示语言模型，分步骤地解决给定问题。
        2.从语言模型的解码器中随机采样，生成一组不同的推理路径。
        3.在众多最终答案中，选择最一致的答案，作为最终的推理结果。

22.Self-Ask
答案：在具身智能和多智能体博弈的场景下，大语言模型要学会判断当前获取的知识是否够用。
    Self-Ask 本质上是通过给大语言模型几个的示例样本（Few-Shot），帮助模型理解在什么情况下，它需要向外界索要更多的外部知识。
    缺点：通过大语言模型自我判断的，多轮思考方法的步数不是特别可控，所以该方法在聊天对话类大模型应用中不太常见。
    使用场景：在具身智能和多智能体博弈的场景则经常会用 Self-Ask 和它的各类变种来实现智能体的自治

23.如何让智能体有记忆
答案：记忆流。记忆流保存了智能体的完整经历，是一个记忆对象的列表，每个对象包含自然语言的描述、创建的时间戳以及最近访问的时间戳。
    记忆流中最基本的元素是记忆事件，这是每个智能体直接感知到的事件。通过记忆流可以帮助智能体理解和适应复杂的情境。
    通过回顾过去的经历，智能体可以更好地理解当前的情境，并做出更合理的决策。同时提高智能体的性能，更有效地管理记忆信息。
    特点：记忆流的检索方法将时近性、重要性和相关性三个因素作为记忆对象的得分，并加权求和作为最终得分。
      1.时近性：为最近访问的记忆对象分配一个更高的分，这和人类的记忆习惯一样，能让刚才或今早发生的事情留在智能体的意识内。
      2.重要性：为智能体觉得重要的记忆对象赋予更高的得分，将关键记忆和普通记忆区分开。
      3.相关性：为与当前情况紧密相关的记忆对象分配一个更高的得分，具体方案可以是用当前情况和记忆事件的高维空间距离来描述其相似性。