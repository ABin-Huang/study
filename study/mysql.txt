1.mysql组件
 server层
  连接器：管理连接，权限验证
  分析器：词法分析、语法分析
  优化器：执行计划生成，索引选择
  执行器：操作存储引擎，返回结果
 存储引擎：存储数据，提供读写接口

2.从更新流程理解redo log(重做日志)和bin log(归档日志)
 时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。
 1.redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
 2.redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
 3.redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
 4.redo log有write pos当前记录的位置 和 checkpoint当前要擦除的位置

 update T set c=c+1 where ID=2;
 1.执行器根据ID=2查找引擎，引擎查找内存或磁盘返回数据，
 2.执行器将c值加1，调用引擎接口写入
 3.引擎将数据更新内存，并将更新日志记录redo log，状态为prepare
 4.执行器生成binlog，并写入磁盘
 5.执行器调引擎提交事务接口，将redo log改成提交状态(两阶段提交)，更新结束。

3.删除主键索引和二级索引有什么影响，如何优化？
 作用：减少碎片空间，页分裂，优化查询速度
 二级索引：主要取决于该索引的大小，会锁定表，二级索引的结构是独立于表数据存储的
 主键索引：由于表数据是按照主键索引的顺序存储的，过程会涉及对表数据的重新组织，可能会扫描整个表
 优化：
  1.ALTER TABLE your_table_name ADD INDEX your_index_name (column_name) ALGORITHM=INPLACE; (5.6版本之后)
  2.使用 Percona 工具,pt-online-schema-change --alter "ADD INDEX your_index_name (column_name)" D=your_database,t=your_table_name
  3.alter table T engine=InnoDB，重建索引 k 的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建

  死锁
  1.innodb_lock_wait_timeout 默认值是 50s，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出
  2.innodb_deadlock_detect 默认on，主动死锁检测，每当一个事务被锁，检查所依赖的线程有没有被其他事务锁住，复杂度是 O(n)，容易引起CPU升高


4.监控mysql
 1.事务方面
   监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill
   在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题

5.参数调优
  innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便(5.6版本后)
  innodb_io_capacity 脏页刷盘速度，设置成磁盘的 IOPS
    使用 fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 计算磁盘随机读写速度
    查询速度下降时可以关注Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total的脏页比例超过75%

  sort_buffer_size 内存排序大小，优先全字段排序，否则rowId，排序字段排序
  max_length_for_sort_data 控制用于排序的行数据的长度的一个参数，单行的长度超过这个值，MySQL 就认为单行太大，使用rowId
  tmp_table_size 内存临时表的大小，默认值是 16M，超过则使用磁盘临时表
  internal_tmp_disk_storage_engine 磁盘临时表使用的引擎默认是 InnoDB

  sync_binlog=N 每次提交事务都 write，但累积 N 个事务后才 fsync。设置为 100~1000，通常与innodb_flush_log_at_trx_commit配置为1
  innodb_flush_log_at_trx_commit 0-事务提交写redo log buffer 1-持久化到磁盘 2-page cache

  binlog_format=‘row’ statement占用空间少，但主备数据可能不一致; mixed会根据语句判断使用哪种日志格式
  slave_parallel_workers 备库设置8~16 之间最好（32 核物理机的情况），执行sql线程
   按表分发线程策略：如果两个事务更新相同的表，直到所有线程中只是一个有冲突，分配到该线程
   按行分发策略：如果两个事务没有更新相同的行，它们在备库上可以并行执行，要考虑主键和唯一索引。占用空间大，解析binlog耗费CPU
   两个方案其实都有一些约束条件：求业务开发人员必须遵守的线上使用规范
       1.要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；
       2.表必须有主键；
       3.不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。

  slave-parallel-type
   DATABASE(5.6):按库分发策略
   LOGICAL_CLOCK(5.7):
  binlog-transaction-dependency-tracking(5.7.22)
   COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。
   WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。
   WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。


6.索引
 1.覆盖索引，只查询二级索引，避免回主表查
   设计方式：1.通过调整顺序，可以少维护一个索引； 2.考虑空间，如name 字段是比 age 字段大的，建议创建一个（name,age) 的联合索引和一个 (age) 的单字段索引
 2.最左前缀原则，联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符
 3.索引下推，在联合索引中，根据前缀索引规则，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数

 4.索引字段使用函数或者表达式不会走索引
 6.索引类型和输入类型不匹配，如果是比较，默认由字符串转整形，隐式类型转换
 7.索引类型编码不同，隐式字符编码转换，会转为超集

7.锁可以分成全局锁、表级锁和行锁三类
 全局锁：对整个数据库实例加锁。Flush tables with read lock；set global readonly=true(不推荐，判断一个库是备库；如果客户端发生异常，则数据库就会一直保持 readonly 状态)
  使用场景：全库逻辑备份，把整库每个表都 select 出来存成文本
 表级锁：
  1.表锁，lock tables … read/write
   使用场景：还没有出现更细粒度的锁，是最常用的处理并发的方式
  2.元数据锁MDL（metadata lock)
   使用场景：5.5 版本，表做增删改查操作加 MDL 读锁；表做结构变更操作加 MDL 写锁
   锁规则：读锁之间不互斥，读写锁之间、写锁之间是互斥
   缺点：如果有大量线程请求读锁，会影响表不能变更。如果表变更缓慢，会影响其他线程读写表
    建议在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程
  3.行锁，引擎实现的

7.语句优化
 查看表索引
 show index from table
 优化表统计信息
 analyze table t

8.排序优化
 使用优先队列排序算法，如果排序字段占用内存小于sort_buffer_size。否则只能使用归并排序算法。

9.问题排查
 1.短连接风暴解决方法：先处理掉那些占着连接但是不工作的线程; 减少连接过程的消耗,跳过权限验证

10.主备延迟原因
 1.备考机器性能差
 2.开发或运营会在备考执行操作，查询占用资源
 3.主库执行大事务
 4.备库的并行复制能力


问题：如何实现隔离级别（读未提交，读已提交，可重复读，串行化）
答案：1）读已提交（记录锁，每一个语句执行前都会重新算出一个新的视图）/可重复读（记录锁+间隙锁，共用一个一致性视图）：MVVC
2）串行化：使用排他锁（exclusive lock）来锁定事务正在读取或修改的数据，防止其他事务对同一数据进行并发操作。

问题：可重复读的底层原理（执行第一个查询语句后创建read view）,很大程度上避免幻读现象（并不是完全解决了），解决的方案有两种：
答案：
    1）针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，
事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，
是查询不出来这条数据的，所以就很好了避免幻读问题。
    2）针对当前读（select ... for update 、update、deleter、insert等语句），是通过 next-key lock（记录锁+间隙锁--锁定范围，如使用范围查询，若其他事务想插入，会生成插入意向锁并阻塞）
方式解决了幻读，
因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，
那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。

具体功能：A创建事务，B随后创建事务，A修改值，B读取值，当A提交完事务，B读取的还是原来的值，并不是A修改后的值。
因为可重复读隔离级别在事务期间读到的记录都是事务启动前的记录（会通过roll_pointer查找undo log，多个版本记录以链表的方式串联起来）

问题：Read View 在 MVCC 里如何工作的？
答案：Read View 中四个字段以及聚簇索引记录中两个跟事务有关的隐藏列
1）m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。
2）min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。
3）max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1；
4）creator_trx_id ：指的是创建该 Read View 的事务的事务 id。

1）.trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里；
2）.roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。

问题：读提交是如何工作的
答案：在每次读取数据时，都会生成一个新的 Read View。



问题：mysql的锁
1）全局锁：用于全库逻辑备份，此时数据库只可读。
优化方法：在可重复读的隔离级别备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。
2）表级锁：
表锁：锁表，只提供读
元数据锁（MDL，防止其他线程对这个表结构做了变更）：1.对一张表进行 CRUD 操作时，加的是 MDL 读锁；  2.对一张表做结构变更操作的时候，加的是 MDL 写锁；
意向锁（只会与表锁冲突，意向锁的目的是为了快速判断表里是否有记录被加锁）： InnoDB 引擎的表里对某些记录加上「共享锁」/「独占锁」之前，要先在表级别加上一个「意向共享锁」/「意向独占锁」；
AUTO-INC 锁；
3）行级锁
Record Lock（ S 锁和 X 锁），记录锁，也就是仅仅把一条记录锁上；
Gap Lock（只存在于可重复读隔离级别，解决幻读），间隙锁，锁定一个范围，但是不包含记录本身；
Next-Key Lock（临键锁）：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。
插入意向锁（特殊的间隙锁，属于行级别锁）：一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁


问题：innodb怎么加行级锁？
答案：加锁的对象是索引，加锁的基本单位是 next-key lock。在一些场景下会退化成记录锁或间隙锁（在能使用记录锁或者间隙锁就能避免幻读现象的场景下， next-key lock 就会退化成记录锁或间隙锁）
加锁规则：除了在二级索引加，还会在主键索引加

问题：如何避免全表扫描
答案：执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了。

segment，region，page，raw