 1.标量和向量的定义
 标量是一个单独的数，小写字母或希腊字母表示
 向量：同时具有大小和方向的几何对象，行向量，列向量

2.如何度量两个向量的相似程度
对于实数和复数，由于定义了它们的绝对值或模，这样我们就可以用这个度量来表示它们的大小(几何上就是长度)，进而可以考察两个实数或复数的距离。
复数x=a+bi的长度或模指的是||x||=√a² +b²

3.向量的范数
 1范数：各向量相加
 2范数：各向量的平方和相加，再开根号
 无穷范数：取最大

4.矩阵范数
1范数：列模和的最大值
无穷范数：行模和的最大值

5.范数的作用
在机器学习的分类问题，判断两个特征向量和矩阵的相似性

6.什么是矩阵的迹?
在线性代数中，一个n*n矩阵A的主对角线(从左上方至右下方的对角线)上各个元素的总和被称为矩阵A的迹或迹数)，一般记作tr(A)
只有方矩阵才有迹

7.特征值、特征向量
设A是n阶矩阵，若存在数入和非零向量X使得Ax=λx(x≠0)则称 入 是4 的一个特征值X 为 A的对应特征值 入的特征向量。
(x为非零向量)

特征值λ是一个标量，它表示矩阵A对特征向量v的缩放因子。换句话说，当矩阵A作用于特征向量v时，结果是v的方向不变，只是长度被缩放了λ倍。
(A-λI)x = 0, 即A-λI = 0。

图像处理：在图像处理中，特征值和特征向量用于图像压缩和特征提取。
主成分分析 (PCA)：在数据降维中，特征值和特征向量用于找到数据的主要方向。
谱聚类：在无监督学习中，特征值和特征向量用于图的分割和聚类

8.计算特征值和特征向量

9.正交投影矩阵
正交投影:向量 y=pW，其中 w为y在 p下的系数向量,
正交投影矩阵:若存在矩阵P，使得pt =y，则称P为正交投影矩阵

10.二次型

11.矩阵的QR分解
矩阵的 QR 分解是一种将矩阵分解为正交矩阵Q和上三角矩阵R的方法。是一种迭代方法。这种分解在数值线性代数中有广泛的应用，
特别是在求解线性方程组、最小二乘问题、特征值问题等方面。QR 分解的形式是：A=QR

求解线性方程组：通过 QR 分解可以将线性方程组Ax=b 转换为Rx=Q T b，进而更容易求解。
最小二乘问题：在最小二乘法中，通过 QR 分解可以有效地求解超定线性方程组。
特征值问题：QR 分解是许多特征值算法（如 QR 算法）的基础。
矩阵秩和条件数：通过 QR 分解可以方便地计算矩阵的秩和条件数。

12.SVD奇异值分解


